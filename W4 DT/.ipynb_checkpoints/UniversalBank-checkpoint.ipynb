{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cdb9f92",
   "metadata": {
    "id": "3cdb9f92"
   },
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f33de8",
   "metadata": {
    "id": "85f33de8"
   },
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ade4bd",
   "metadata": {
    "id": "c6ade4bd"
   },
   "source": [
    "# 2. Load the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "192YtAnVTkHD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "192YtAnVTkHD",
    "outputId": "201b365c-9497-4724-acc9-24b75bb36605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gopi Chand\\OneDrive - University of South Florida\\Desktop\\DSP\\W4 DT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4fe7dcf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "f4fe7dcf",
    "outputId": "252c3d22-3aea-4086-d196-4c48f90d5653"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Income</th>\n",
       "      <th>ZIP Code</th>\n",
       "      <th>Family</th>\n",
       "      <th>CCAvg</th>\n",
       "      <th>Education</th>\n",
       "      <th>Mortgage</th>\n",
       "      <th>Personal Loan</th>\n",
       "      <th>Securities Account</th>\n",
       "      <th>CD Account</th>\n",
       "      <th>Online</th>\n",
       "      <th>CreditCard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>91107</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>34</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>100</td>\n",
       "      <td>94112</td>\n",
       "      <td>1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>45</td>\n",
       "      <td>91330</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>92121</td>\n",
       "      <td>4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>27</td>\n",
       "      <td>72</td>\n",
       "      <td>91711</td>\n",
       "      <td>2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>50</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>93943</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>81</td>\n",
       "      <td>90089</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>180</td>\n",
       "      <td>93023</td>\n",
       "      <td>1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>65</td>\n",
       "      <td>39</td>\n",
       "      <td>105</td>\n",
       "      <td>94710</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>90277</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>23</td>\n",
       "      <td>114</td>\n",
       "      <td>93106</td>\n",
       "      <td>2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>59</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>94920</td>\n",
       "      <td>4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>67</td>\n",
       "      <td>41</td>\n",
       "      <td>112</td>\n",
       "      <td>91741</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>95054</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>38</td>\n",
       "      <td>14</td>\n",
       "      <td>130</td>\n",
       "      <td>95010</td>\n",
       "      <td>4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3</td>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>42</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "      <td>94305</td>\n",
       "      <td>4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>193</td>\n",
       "      <td>91604</td>\n",
       "      <td>2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>55</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>94720</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID  Age  Experience  Income  ZIP Code  Family  CCAvg  Education  Mortgage  \\\n",
       "0    1   25           1      49     91107       4    1.6          1         0   \n",
       "1    2   45          19      34     90089       3    1.5          1         0   \n",
       "2    3   39          15      11     94720       1    1.0          1         0   \n",
       "3    4   35           9     100     94112       1    2.7          2         0   \n",
       "4    5   35           8      45     91330       4    1.0          2         0   \n",
       "5    6   37          13      29     92121       4    0.4          2       155   \n",
       "6    7   53          27      72     91711       2    1.5          2         0   \n",
       "7    8   50          24      22     93943       1    0.3          3         0   \n",
       "8    9   35          10      81     90089       3    0.6          2       104   \n",
       "9   10   34           9     180     93023       1    8.9          3         0   \n",
       "10  11   65          39     105     94710       4    2.4          3         0   \n",
       "11  12   29           5      45     90277       3    0.1          2         0   \n",
       "12  13   48          23     114     93106       2    3.8          3         0   \n",
       "13  14   59          32      40     94920       4    2.5          2         0   \n",
       "14  15   67          41     112     91741       1    2.0          1         0   \n",
       "15  16   60          30      22     95054       1    1.5          3         0   \n",
       "16  17   38          14     130     95010       4    4.7          3       134   \n",
       "17  18   42          18      81     94305       4    2.4          1         0   \n",
       "18  19   46          21     193     91604       2    8.1          3         0   \n",
       "19  20   55          28      21     94720       1    0.5          2         0   \n",
       "\n",
       "    Personal Loan  Securities Account  CD Account  Online  CreditCard  \n",
       "0               0                   1           0       0           0  \n",
       "1               0                   1           0       0           0  \n",
       "2               0                   0           0       0           0  \n",
       "3               0                   0           0       0           0  \n",
       "4               0                   0           0       0           1  \n",
       "5               0                   0           0       1           0  \n",
       "6               0                   0           0       1           0  \n",
       "7               0                   0           0       0           1  \n",
       "8               0                   0           0       1           0  \n",
       "9               1                   0           0       0           0  \n",
       "10              0                   0           0       0           0  \n",
       "11              0                   0           0       1           0  \n",
       "12              0                   1           0       0           0  \n",
       "13              0                   0           0       1           0  \n",
       "14              0                   1           0       0           0  \n",
       "15              0                   0           0       1           1  \n",
       "16              1                   0           0       0           0  \n",
       "17              0                   0           0       0           0  \n",
       "18              1                   0           0       0           0  \n",
       "19              0                   1           0       0           1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loding the data file\n",
    "bank_df = pd.read_csv('UniversalBank.csv')\n",
    "bank_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508825eb",
   "metadata": {
    "id": "508825eb"
   },
   "source": [
    "# 3. Explore the given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f0b8c5",
   "metadata": {
    "id": "22f0b8c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Age', 'Experience', 'Income', 'ZIP Code', 'Family', 'CCAvg',\n",
       "       'Education', 'Mortgage', 'Personal Loan', 'Securities Account',\n",
       "       'CD Account', 'Online', 'CreditCard'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#see the column name\n",
    "bank_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f40da281",
   "metadata": {
    "id": "f40da281"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'AGE', 'EXPERIENCE', 'INCOME', 'ZIP_CODE', 'FAMILY', 'CCAVG',\n",
       "       'EDUCATION', 'MORTGAGE', 'PERSONAL_LOAN', 'SECURITIES_ACCOUNT',\n",
       "       'CD_ACCOUNT', 'ONLINE', 'CREDITCARD'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Coverting all column name to Upper alphabtes and replacing space with \"_\"\n",
    "bank_df.columns = [s.strip().upper().replace(' ', '_') for s in bank_df.columns] \n",
    "bank_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af8dc08",
   "metadata": {
    "id": "4af8dc08"
   },
   "outputs": [],
   "source": [
    "#Some of the variables aren't predictors; therefore we drop them\n",
    "# drop ID, and Zip Code as predictors\n",
    "bank_df = bank_df.drop(columns=['ID', 'ZIP_CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f8918c",
   "metadata": {
    "id": "c1f8918c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                   0\n",
       "EXPERIENCE            0\n",
       "INCOME                0\n",
       "FAMILY                0\n",
       "CCAVG                 0\n",
       "EDUCATION             0\n",
       "MORTGAGE              0\n",
       "PERSONAL_LOAN         0\n",
       "SECURITIES_ACCOUNT    0\n",
       "CD_ACCOUNT            0\n",
       "ONLINE                0\n",
       "CREDITCARD            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for if there is any missing values in remaining columns\n",
    "bank_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2271d95",
   "metadata": {
    "id": "b2271d95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                     int64\n",
       "EXPERIENCE              int64\n",
       "INCOME                  int64\n",
       "FAMILY                  int64\n",
       "CCAVG                 float64\n",
       "EDUCATION               int64\n",
       "MORTGAGE                int64\n",
       "PERSONAL_LOAN           int64\n",
       "SECURITIES_ACCOUNT      int64\n",
       "CD_ACCOUNT              int64\n",
       "ONLINE                  int64\n",
       "CREDITCARD              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking data type of each cloumns\n",
    "bank_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd3f98c",
   "metadata": {
    "id": "4dd3f98c"
   },
   "source": [
    "only CCAVG column is float and remaining all are integers, we need to change fAMILY,EDUCATION,PERSONAL_LOAN, SECURITIES_ACCOUNT,CD_ACCOUNT,ONLINE and CREDITCARD as category data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5baa1619",
   "metadata": {
    "id": "5baa1619"
   },
   "outputs": [],
   "source": [
    "bank_df.FAMILY = bank_df.FAMILY.astype('category')\n",
    "bank_df.SECURITIES_ACCOUNT = bank_df.SECURITIES_ACCOUNT.astype('category')\n",
    "bank_df.EDUCATION = bank_df.EDUCATION.astype('category')\n",
    "bank_df.CD_ACCOUNT = bank_df.CD_ACCOUNT.astype('category')\n",
    "bank_df.ONLINE = bank_df.ONLINE.astype('category')\n",
    "bank_df.CD_ACCOUNT = bank_df.CD_ACCOUNT.astype('category')\n",
    "bank_df.CREDITCARD = bank_df.CREDITCARD.astype('category')\n",
    "bank_df.PERSONAL_LOAN = bank_df.PERSONAL_LOAN.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f0a274e",
   "metadata": {
    "id": "5f0a274e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AGE                      int64\n",
       "EXPERIENCE               int64\n",
       "INCOME                   int64\n",
       "FAMILY                category\n",
       "CCAVG                  float64\n",
       "EDUCATION             category\n",
       "MORTGAGE                 int64\n",
       "PERSONAL_LOAN         category\n",
       "SECURITIES_ACCOUNT    category\n",
       "CD_ACCOUNT            category\n",
       "ONLINE                category\n",
       "CREDITCARD            category\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8669338b",
   "metadata": {
    "id": "8669338b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>EXPERIENCE</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>CCAVG</th>\n",
       "      <th>MORTGAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.338400</td>\n",
       "      <td>20.104600</td>\n",
       "      <td>73.774200</td>\n",
       "      <td>1.937938</td>\n",
       "      <td>56.498800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.463166</td>\n",
       "      <td>11.467954</td>\n",
       "      <td>46.033729</td>\n",
       "      <td>1.747659</td>\n",
       "      <td>101.713802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>67.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>224.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>635.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AGE   EXPERIENCE       INCOME        CCAVG     MORTGAGE\n",
       "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000\n",
       "mean     45.338400    20.104600    73.774200     1.937938    56.498800\n",
       "std      11.463166    11.467954    46.033729     1.747659   101.713802\n",
       "min      23.000000    -3.000000     8.000000     0.000000     0.000000\n",
       "25%      35.000000    10.000000    39.000000     0.700000     0.000000\n",
       "50%      45.000000    20.000000    64.000000     1.500000     0.000000\n",
       "75%      55.000000    30.000000    98.000000     2.500000   101.000000\n",
       "max      67.000000    43.000000   224.000000    10.000000   635.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "855e1995",
   "metadata": {
    "id": "855e1995"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4698\n",
       "1     302\n",
       "Name: CD_ACCOUNT, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bank_df.CD_ACCOUNT.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92179c56",
   "metadata": {
    "id": "92179c56"
   },
   "source": [
    "By seeing above we can say that our data is imblanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b7e0a4",
   "metadata": {
    "id": "f2b7e0a4"
   },
   "source": [
    "# 4. Split data (train/test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8707a465",
   "metadata": {
    "id": "8707a465"
   },
   "outputs": [],
   "source": [
    "# split the data into validation and training set\n",
    "df_train, df_test = train_test_split(bank_df, test_size=0.3, random_state=1)\n",
    "\n",
    "# to reduce repetition in later code, create variables to represent the columns\n",
    "# that are our predictors and target\n",
    "target = 'CD_ACCOUNT'\n",
    "predictors = list(bank_df.columns)\n",
    "predictors.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb9e341",
   "metadata": {
    "id": "7eb9e341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AGE', 'EXPERIENCE', 'INCOME', 'FAMILY', 'CCAVG', 'EDUCATION', 'MORTGAGE', 'PERSONAL_LOAN', 'SECURITIES_ACCOUNT', 'ONLINE', 'CREDITCARD']\n"
     ]
    }
   ],
   "source": [
    "print(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf930a2",
   "metadata": {
    "id": "3bf930a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CD_ACCOUNT\n"
     ]
    }
   ],
   "source": [
    "print(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54062d70",
   "metadata": {
    "id": "54062d70"
   },
   "source": [
    "# 5. Standardize numeric values\n",
    "Now, let's create a common scale between the numberic columns by standardizing each numeric column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9870a9f7",
   "metadata": {
    "id": "9870a9f7"
   },
   "outputs": [],
   "source": [
    "# create a standard scaler and fit it to the training set of predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(df_train[predictors])\n",
    "\n",
    "# Transform the predictors of training and test sets\n",
    "train_predictors = scaler.transform(df_train[predictors]) # train_predictors is not a numpy array\n",
    "train_target = df_train[target] # train_target is now a series object\n",
    "\n",
    "validation_predictors = scaler.transform(df_test[predictors]) # validation_target is now a series object\n",
    "validation_target = df_test[target] # validation_target is now a series object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90782e5d",
   "metadata": {
    "id": "90782e5d"
   },
   "outputs": [],
   "source": [
    "X_train = df_train[predictors]\n",
    "y_train = df_train[target]\n",
    "X_test = df_test[predictors]\n",
    "y_test = df_test[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Cx5tgoyDX3Pb",
   "metadata": {
    "id": "Cx5tgoyDX3Pb"
   },
   "source": [
    "#Address any data imbalances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27875a5f",
   "metadata": {
    "id": "Yuokx4s8Xx-i"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3281\n",
       "1    3281\n",
       "Name: CD_ACCOUNT, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We will utilize an oversamplying technique to address any necessary date balancing.\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "target = 'CD_ACCOUNT'\n",
    "predictors = list(bank_df.columns)\n",
    "predictors.remove(target)\n",
    "RanOverSample=RandomOverSampler(sampling_strategy=1)\n",
    "pred,tar = RanOverSample.fit_resample(df_train[predictors],df_train[target])\n",
    "tar.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fb68be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8044f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "742b7acb",
   "metadata": {
    "id": "742b7acb"
   },
   "source": [
    "# 6.0 Model the data\n",
    "First, we will create a dataframe to hold all the results of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55499c66",
   "metadata": {
    "id": "55499c66"
   },
   "outputs": [],
   "source": [
    "#performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff9db71",
   "metadata": {
    "id": "cff9db71"
   },
   "source": [
    "# 6.1 Fit a LogisticRegression model with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa34ed3c",
   "metadata": {
    "id": "fa34ed3c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "301da93d",
   "metadata": {
    "id": "301da93d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gopi Chand\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 20 is smaller than n_iter=100. Running 20 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n",
      "The best recall score is 0.6662337662337662\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 100}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 10\n",
    "param_grid = { 'solver': [ 'liblinear', 'saga'],\n",
    "                      'penalty': ['l1', 'l2'], # NOTE: 'elasticnet' is only supported by 'saga' solver\n",
    "                      'C': [100, 10, 1.0, 0.1, 0.01],\n",
    "                      # number of iterations to converge (sometimes the default is not enough - and sometimes, it will never converge)\n",
    "                     }\n",
    "logi_reg = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = logi_reg, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_logi_reg_rand = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06642b55",
   "metadata": {
    "id": "06642b55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.6024096385542169\n",
      "************************************\n",
      "Accuracy Score:   0.978\n",
      "Precision Score:  1.0\n",
      "F1 Score:         0.7518796992481204\n",
      "************************************\n",
      "Confusion Matrix: [[1417    0]\n",
      " [  33   50]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = rand_search.predict(X_test)\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a7ea77",
   "metadata": {
    "id": "f0a7ea77"
   },
   "source": [
    "# 6.2 Fit a LogisticRegression model with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2e4c5c64",
   "metadata": {
    "id": "2e4c5c64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "The best recall score is 0.6662337662337662\n",
      "... with parameters: {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 10\n",
    "\n",
    "penalty= rand_search.best_params_['penalty']\n",
    "solver =rand_search.best_params_['solver']\n",
    "\n",
    "param_grid = {\n",
    "    'C': [100, 10, 1.0, 0.1, 0.01],\n",
    "    'penalty': [penalty],\n",
    "    'solver': [solver]\n",
    "}\n",
    "\n",
    "logi_reg = LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = logi_reg, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_SVM_linear = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "851a7906",
   "metadata": {
    "id": "851a7906"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.6024096385542169\n",
      "************************************\n",
      "Accuracy Score:   0.978\n",
      "Precision Score:  1.0\n",
      "F1 Score:         0.7518796992481204\n",
      "************************************\n",
      "Confusion Matrix: [[1417    0]\n",
      " [  33   50]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4fd3a8",
   "metadata": {
    "id": "db4fd3a8"
   },
   "source": [
    "# 6.1 Fit a SVM classification model using linear kernal with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fed511f1",
   "metadata": {
    "id": "fed511f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gopi Chand\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 5 is smaller than n_iter=50. Running 5 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best recall score is 0.6662790697674419\n",
      "... with parameters: {'C': 100}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C': np.arange(5,15)\n",
    "}\n",
    "\n",
    "svm_linear_model = SVC(kernel=\"linear\")\n",
    "rand_search = RandomizedSearchCV(estimator = svm_linear_model, param_distributions=param_grid, cv=kfolds, n_iter=15,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,\n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_SVM_linear = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fcaf0c3",
   "metadata": {
    "id": "9fcaf0c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.6024096385542169\n",
      "************************************\n",
      "Accuracy Score:   0.978\n",
      "Precision Score:  1.0\n",
      "F1 Score:         0.7518796992481204\n",
      "************************************\n",
      "Confusion Matrix: [[1417    0]\n",
      " [  33   50]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = rand_search.predict(X_test)\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a56725",
   "metadata": {
    "id": "69a56725"
   },
   "source": [
    "# 6.2 Fit a SVM classification model using linear kernal with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2352b008",
   "metadata": {
    "id": "2352b008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3 candidates, totalling 6 fits\n",
      "The best recall score is 0.6665971643035863\n",
      "... with parameters: {'C': 110}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 2\n",
    "\n",
    "C = rand_search.best_params_['C']\n",
    "\n",
    "param_grid = {\n",
    "    'C': [C+1,C,C-1]\n",
    "}\n",
    "\n",
    "svm_linear_model = SVC(kernel=\"linear\")\n",
    "grid_search = GridSearchCV(estimator = svm_linear_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_SVM_linear = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa4379b2",
   "metadata": {
    "id": "aa4379b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Recall Score:     0.6024096385542169\n",
      "************************************\n",
      "Accuracy Score:   0.978\n",
      "Precision Score:  1.0\n",
      "F1 Score:         0.7518796992481204\n",
      "************************************\n",
      "Confusion Matrix: [[1417    0]\n",
      " [  33   50]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826f16df",
   "metadata": {
    "id": "826f16df"
   },
   "source": [
    "# # 6.5 Fit a SVM classification model using Polynomial kernal with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fa8d11",
   "metadata": {
    "id": "27fa8d11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_rand = {\n",
    "    'C': np.arange(5,15),\n",
    "    'degree': [3, 4,5],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'coef0': np.arange(1,5)\n",
    "}\n",
    "\n",
    "svm_poly_model = SVC(kernel=\"poly\")\n",
    "rand_search = RandomizedSearchCV(estimator = svm_poly_model, param_distributions=param_rand, cv=kfolds, n_iter=50,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train,np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "best_SVM_poly = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c3092",
   "metadata": {
    "id": "fa9c3092"
   },
   "outputs": [],
   "source": [
    "y_pred = rand_search.predict(X_test)\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fbf46e",
   "metadata": {
    "id": "35fbf46e"
   },
   "source": [
    "# # 6.5 Fit a SVM classification model using Polynomial kernal with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65522a6c",
   "metadata": {
    "id": "65522a6c"
   },
   "outputs": [],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "degree = rand_search.best_params_['degree']\n",
    "gamma = rand_search.best_params_['gamma']\n",
    "coef0 = rand_search.best_params_['coef0']\n",
    "C = rand_search.best_params_['C']\n",
    "param_grid = {\n",
    "    'C': [C-1,C,C+1],\n",
    "    'degree': np.arange(degree-2,degree+2),\n",
    "    'gamma': [gamma],\n",
    "    'coef0': np.arange(coef0-2,coef0+2),\n",
    "}\n",
    "\n",
    "svm_poly_model = SVC(kernel=\"poly\")\n",
    "grid_search = GridSearchCV(estimator = svm_poly_model, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "best_SVM_poly = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d15f82",
   "metadata": {
    "id": "d9d15f82"
   },
   "outputs": [],
   "source": [
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1eb85e3",
   "metadata": {
    "id": "b1eb85e3"
   },
   "source": [
    "# 6.6 Fit a Decision Tree Classifier model with Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jXQCtF2lA6x1",
   "metadata": {
    "id": "jXQCtF2lA6x1"
   },
   "outputs": [],
   "source": [
    "# Criterion used to guide data splits\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "# Maximum number of levels in tree. If None, then nodes are expanded until all leaves are pure or until all \n",
    "# leaves contain less than min_samples_split samples.\n",
    "# default = None\n",
    "max_depth = [int(x) for x in np.linspace(1, 40000, 50)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "# default is 2\n",
    "min_samples_split = [int(x) for x in np.linspace(2, 5000, 50)]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "# default = 1 \n",
    "min_samples_leaf = [int(x) for x in np.linspace(1, 10000, 50)]\n",
    "\n",
    "# max_leaf_nodes  - Grow trees with max_leaf_nodes in best-first fashion.\n",
    "# If None then unlimited number of leaf nodes.\n",
    "# default=None \n",
    "max_leaf_nodes = [int(x) for x in np.linspace(2, len(y_test), 50)]\n",
    "max_leaf_nodes.append(None)\n",
    "\n",
    "# min_impurity_decrease - A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "# default=0.0\n",
    "min_impurity_decrease = [x for x in np.arange(0.0, 0.01, 0.0001).round(5)]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid_random = { 'criterion': criterion,\n",
    "                      'max_depth': max_depth,\n",
    "                      'min_samples_split': min_samples_split,\n",
    "                      'min_samples_leaf' : min_samples_leaf,\n",
    "                      'max_leaf_nodes' : max_leaf_nodes,\n",
    "                      'min_impurity_decrease' : min_impurity_decrease,\n",
    "                     }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fAZWqHgBGb3",
   "metadata": {
    "id": "9fAZWqHgBGb3"
   },
   "outputs": [],
   "source": [
    "dtree_default = DecisionTreeClassifier()\n",
    "\n",
    "best_random_search_model = RandomizedSearchCV(\n",
    "        estimator=DecisionTreeClassifier(), \n",
    "        scoring='recall', \n",
    "        param_distributions=param_grid_random, \n",
    "        n_iter = 300, \n",
    "        cv=10, \n",
    "        verbose=1, \n",
    "        n_jobs = -1\n",
    "    )\n",
    "_ = best_random_search_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4r-R4JrCBV3r",
   "metadata": {
    "id": "4r-R4JrCBV3r"
   },
   "outputs": [],
   "source": [
    "random_search_best_params = best_random_search_model.best_params_\n",
    "print('Best parameters found: ', random_search_best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bIChK0JDPhk",
   "metadata": {
    "id": "9bIChK0JDPhk"
   },
   "outputs": [],
   "source": [
    "y_pred = best_random_search_model.predict(X_test)\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qCpDjRWMFkTd",
   "metadata": {
    "id": "qCpDjRWMFkTd"
   },
   "outputs": [],
   "source": [
    "#The best parameters found using RandomizedSearchCV were:\n",
    "random_search_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TeVG82BTFyFM",
   "metadata": {
    "id": "TeVG82BTFyFM"
   },
   "source": [
    "Let's now use these current best parameters as a starting point for a more refined grid search. We'll use the same parameters as before, but we'll use a much smaller range of values for each parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609701cc",
   "metadata": {
    "id": "609701cc"
   },
   "source": [
    "# 6.7 Fit a Decision Tree Classifier model with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15da7ff",
   "metadata": {
    "id": "e15da7ff"
   },
   "outputs": [],
   "source": [
    "plus_minus = 10 \n",
    "increment = 2\n",
    "\n",
    "param_grid = { 'min_samples_split': [x for x in range(random_search_best_params['min_samples_split']-plus_minus, random_search_best_params['min_samples_split']+plus_minus,2) if x >= 2],       \n",
    "              'min_samples_leaf': [x for x in range(random_search_best_params['min_samples_leaf']-plus_minus , random_search_best_params['min_samples_leaf']+plus_minus,2) if x > 0],\n",
    "              'min_impurity_decrease': [x for x in np.arange(random_search_best_params['min_impurity_decrease']-0.001, random_search_best_params['min_impurity_decrease']+0.001,.0001).round(5) if x >= 0.000],\n",
    "              'max_leaf_nodes':[x for x in range(random_search_best_params['max_leaf_nodes']-plus_minus , random_search_best_params['max_leaf_nodes']+plus_minus, 2) if x > 1],  \n",
    "              'max_depth': [x for x in range(random_search_best_params['max_depth']-plus_minus , random_search_best_params['max_depth']+plus_minus, 2) if x > 1],\n",
    "              'criterion': [random_search_best_params['criterion']]\n",
    "              }\n",
    "\n",
    "best_grid_search_model = GridSearchCV(estimator=DecisionTreeClassifier(), \n",
    "                                    scoring='recall', param_grid=param_grid, cv=5, verbose=1,  n_jobs = -1)\n",
    "_ = best_grid_search_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "okpWdfLjF6sJ",
   "metadata": {
    "id": "okpWdfLjF6sJ"
   },
   "outputs": [],
   "source": [
    "print('Best parameters found: ', best_grid_search_model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rk88XxiYF7Cb",
   "metadata": {
    "id": "rk88XxiYF7Cb"
   },
   "outputs": [],
   "source": [
    "y_pred = best_grid_search_model.predict(X_test)\n",
    "print(\"************************************\")\n",
    "print(f\"{'Recall Score:':18}{recall_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Accuracy Score: ':18}{accuracy_score(y_test, y_pred)}\")\n",
    "print(f\"{'Precision Score: ':18}{precision_score(y_test, y_pred)}\")\n",
    "print(f\"{'F1 Score: ':18}{f1_score(y_test, y_pred)}\")\n",
    "print(\"************************************\")\n",
    "print(f\"{'Confusion Matrix: ':18}{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qn19mAmvIFkD",
   "metadata": {
    "id": "Qn19mAmvIFkD"
   },
   "outputs": [],
   "source": [
    "print(\"************************************\")\n",
    "print(\"************************************\")\n",
    "print(\"************************************\")\n",
    "print(\"*******Enter the Recall score of all models*****************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883c71a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
